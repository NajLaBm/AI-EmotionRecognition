# 🎭 AI-EmotionRecognition

(Juste un partie du code)
Un projet d'intelligence artificielle pour la détection des émotions à partir du texte, de l'audio et des images(expressions faciales et gestuelles).

📌 Fonctionnalités
✅ Détection des émotions à partir d'images faciales, la posture et la position des mains 🖼️
✅ Analyse des émotions dans le texte 📝
✅ Reconnaissance des émotions dans l’audio 🔊
✅ Utilisation de MediaPipe, CNN-LSTM, BERT et attention mechanism
✅ Déploiement sous forme d’application web 🌐 avec Flask

🗂️ Bases de données utilisées
Bases de données internes : Données collectées et annotées en 7 émotions
Ravdess+SAVEE+TESS : Conbinaison de données
TextEmotion : Collection de tweets


🔧 Technologies utilisées
Python 🐍
TensorFlow 
MediaPipe pour la détection des visages et des mains
BERT pour le traitement du langage naturel (NLP)
Librosa pour l’analyse audio
Flask pour le backend web

📊 Résultats et performances
Modèle image : 98,74% de précision
Modèle texte : 75% de précision
Modèle audio : 93,48% de précision

🎯 Améliorations futures
Intégration de modèles plus avancés
Optimisation du temps de traitement
Migration vers un projet multimodal
