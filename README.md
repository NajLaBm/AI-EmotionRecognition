# ğŸ­ AI-EmotionRecognition

(Juste un partie du code)
Un projet d'intelligence artificielle pour la dÃ©tection des Ã©motions Ã  partir du texte, de l'audio et des images(expressions faciales et gestuelles).

ğŸ“Œ FonctionnalitÃ©s
âœ… DÃ©tection des Ã©motions Ã  partir d'images faciales, la posture et la position des mains ğŸ–¼ï¸
âœ… Analyse des Ã©motions dans le texte ğŸ“
âœ… Reconnaissance des Ã©motions dans lâ€™audio ğŸ”Š
âœ… Utilisation de MediaPipe, CNN-LSTM, BERT et attention mechanism
âœ… DÃ©ploiement sous forme dâ€™application web ğŸŒ avec Flask

ğŸ—‚ï¸ Bases de donnÃ©es utilisÃ©es
Bases de donnÃ©es internes : DonnÃ©es collectÃ©es et annotÃ©es en 7 Ã©motions
Ravdess+SAVEE+TESS : Conbinaison de donnÃ©es
TextEmotion : Collection de tweets


ğŸ”§ Technologies utilisÃ©es
Python ğŸ
TensorFlow 
MediaPipe pour la dÃ©tection des visages et des mains
BERT pour le traitement du langage naturel (NLP)
Librosa pour lâ€™analyse audio
Flask pour le backend web

ğŸ“Š RÃ©sultats et performances
ModÃ¨le image : 98,74% de prÃ©cision
ModÃ¨le texte : 75% de prÃ©cision
ModÃ¨le audio : 93,48% de prÃ©cision

ğŸ¯ AmÃ©liorations futures
IntÃ©gration de modÃ¨les plus avancÃ©s
Optimisation du temps de traitement
Migration vers un projet multimodal
